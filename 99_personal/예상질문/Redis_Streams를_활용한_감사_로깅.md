## Q1. 감사 로깅을 별도로 구축하게 된 배경은 무엇인가요?

운영 요구사항으로 로그인 이력뿐 아니라 콘텐츠 생성, 수정, 삭제, 권한 변경, 회원 관리까지 모든 CRUD 작업에 대한 감사 추적이 필요했습니다. 그런데 기존 로깅은 SLF4J로 애플리케이션 로그 파일에만 기록하는 구조여서, 관리자가 특정 시점의 변경 이력을 검색하거나 조회하는 게 사실상 불가능했습니다. 감사 데이터를 DB에 저장해서 검색 가능한 형태로 관리할 필요가 있었고, 동시에 감사 로깅이 핵심 비즈니스 로직의 성능에 영향을 주지 않아야 했기 때문에 비동기 방식을 채택하게 되었습니다.

---

## Q2. DB에 직접 쓰지 않고 Redis Streams를 중간에 둔 이유는 무엇인가요?

CMS 특성상 수백 명의 사용자가 동시에 게시글을 작성하고 수정하기 때문에 감사 이벤트 빈도가 상당히 높습니다. 이걸 매번 동기적으로 DB에 INSERT하면 핵심 트랜잭션에 쓰기 부하가 가중되고, 감사 로깅 테이블의 락이 본래 비즈니스 쿼리에 영향을 줄 수 있습니다. Redis Streams를 버퍼로 두면 비즈니스 로직에서는 Redis에 이벤트만 빠르게 발행하고 바로 반환되기 때문에 API 응답 시간에 거의 영향을 주지 않습니다. Consumer가 별도로 Redis Streams에서 이벤트를 소비해서 DB에 배치로 적재하는 구조여서 쓰기 부하를 분산할 수 있었습니다.

---

## Q3. AOP로 감사 로깅을 구현한 방식을 설명해 주세요.

감사 대상 메서드에 커스텀 어노테이션을 붙이고, AOP로 해당 메서드 실행 전후를 가로채서 감사 이벤트를 생성하는 방식입니다. 어노테이션에는 이벤트 유형이나 대상 리소스 같은 메타 정보를 명시하고, AOP Advice에서 실행 컨텍스트인 사용자 정보, 요청 파라미터, 실행 결과를 수집해서 감사 이벤트 객체를 만듭니다. 이렇게 만들어진 이벤트를 Redis Streams에 발행하는 것까지가 AOP의 역할입니다. 비즈니스 로직 코드에 감사 로깅 코드가 침투하지 않기 때문에, 감사 대상을 추가하거나 변경할 때 비즈니스 코드를 수정할 필요가 없습니다.

---

## Q4. Redis Streams의 Consumer 구조는 어떻게 되어 있나요?

Consumer Group을 구성해서 이벤트를 소비합니다. Producer인 AOP에서 감사 이벤트를 Stream에 XADD로 발행하면, Consumer Group에 속한 Consumer가 XREADGROUP으로 이벤트를 읽어서 DB에 적재합니다. Consumer는 이벤트를 처리한 뒤 XACK으로 처리 완료를 알려서, 장애가 발생하더라도 ACK되지 않은 이벤트는 재처리될 수 있도록 보장합니다. 현재는 단일 Consumer로 운영하고 있지만, Consumer Group 구조이기 때문에 처리량이 늘어나면 Consumer를 추가해서 수평 확장할 수 있습니다.

---

## Q5. Consumer가 DB에 적재할 때 배치로 처리하나요, 건건이 처리하나요?

건건이 처리하는 방식을 기본으로 하되, Consumer가 이벤트를 읽을 때 한 번에 여러 건을 가져오는 구조입니다. XREADGROUP에서 COUNT 옵션으로 한 번에 읽어올 이벤트 수를 지정하고, 읽어온 이벤트들을 순차적으로 DB에 INSERT합니다. 감사 로그의 특성상 데이터 유실이 있으면 안 되기 때문에, 건별로 INSERT하고 성공한 건에 대해서만 ACK를 보내는 방식으로 안정성을 우선했습니다. 처리량이 크게 늘어나면 배치 INSERT로 전환하는 것도 고려할 수 있습니다.

---

## Q6. k6 부하 테스트 환경과 결과를 설명해 주세요.

k6으로 최대 300 VU, 평균 80에서 120 RPS 수준의 부하를 걸어서 테스트했습니다. 이 환경에서 감사 이벤트 발생량이 초당 약 1,000건 수준까지 올라갔는데, Consumer의 backlog가 평균 0에서 5 범위로 안정적으로 유지되었습니다. backlog가 낮다는 건 이벤트가 발행되는 속도를 Consumer가 충분히 따라가고 있다는 의미입니다. 가장 중요한 건 감사 로깅 활성화 전후로 API의 p95 응답 시간 증가 폭이 5ms 이하였다는 점인데, 이는 Redis Streams에 이벤트를 발행하는 오버헤드가 핵심 트랜잭션 성능에 실질적으로 영향을 주지 않는다는 걸 검증한 것입니다.

---

## Q7. p95 응답 시간을 기준으로 잡은 이유는 무엇인가요?

평균 응답 시간은 극단적으로 빠른 요청들이 느린 요청의 영향을 희석시키기 때문에, 실제 사용자 경험을 정확히 반영하지 못합니다. p95는 전체 요청 중 95퍼센트가 이 시간 안에 응답된다는 의미이기 때문에, 대부분의 사용자가 체감하는 최악의 응답 시간에 가까운 지표입니다. 감사 로깅처럼 모든 요청에 부착되는 기능은 꼬리 지연에 영향을 줄 수 있으니까, p95를 기준으로 전후 비교하는 게 성능 영향을 판단하는 데 가장 적합하다고 판단했습니다.

---

## Q8. Redis Streams에 장애가 발생하면 감사 이벤트가 유실되지 않나요?

Redis 자체에 장애가 생기면 이벤트 발행이 실패할 수 있습니다. 이 경우 AOP에서 Redis 발행 실패를 감지하면 로컬 파일 로그로 폴백해서 기록합니다. 서비스의 핵심 트랜잭션이 감사 로깅 실패 때문에 같이 실패하면 안 되기 때문에, 감사 이벤트 발행은 예외가 전파되지 않도록 처리했습니다. Redis가 복구되면 다시 정상적으로 Streams에 발행됩니다. 폴백된 로그는 수동 또는 별도 배치로 DB에 적재할 수 있는데, 인증 시스템의 Graceful Degradation과 같은 원칙을 적용한 것입니다.

---

## Q9. 이 구조에서 개선하고 싶은 점이 있다면 무엇인가요?

두 가지를 개선하고 싶습니다. 첫째, 현재는 Consumer가 단일 인스턴스로 동작하고 있는데, 이벤트 처리량이 늘어나면 Consumer를 여러 개로 확장해야 합니다. Consumer Group 구조이기 때문에 확장 자체는 어렵지 않지만, 순서 보장이 필요한 이벤트와 그렇지 않은 이벤트를 구분하는 파티셔닝 전략이 필요합니다. 둘째, 감사 로그가 계속 누적되면 DB 조회 성능이 떨어질 수 있는데, 일정 기간이 지난 감사 로그를 아카이빙하는 생명주기 관리 정책을 도입하면 장기 운영 안정성을 확보할 수 있을 것입니다. 이런 개선을 통해 감사 로깅 시스템의 확장성과 운영 효율을 한 단계 더 높일 수 있을 것입니다.