# k6_부하_테스트

---

## Q1. k6가 뭔가요? 다른 부하 테스트 도구와 비교했을 때 장점은 무엇인가요?

k6는 Grafana Labs에서 만든 오픈소스 부하 테스트 도구입니다. JavaScript로 테스트 시나리오를 작성하고, Go 런타임으로 실행되기 때문에 스크립트 작성은 쉬우면서 실행 성능은 높습니다. JMeter는 GUI 기반이라 직관적이지만 대규모 테스트 시 JVM 메모리 소모가 크고, Locust는 Python 기반이라 작성은 편하지만 단일 프로세스 성능이 k6보다 낮습니다. k6는 CLI 기반이라 CI/CD 파이프라인에 통합하기 좋고, VU 단위로 동시 사용자를 시뮬레이션하기 때문에 시나리오 설계가 직관적입니다.

---

## Q2. VU와 RPS의 차이는 무엇인가요?

VU는 Virtual User로 동시에 테스트를 실행하는 가상 사용자 수입니다. RPS는 Requests Per Second로 초당 서버에 도달하는 요청 수입니다. VU가 300이라고 해서 RPS가 300인 건 아닙니다. 각 VU가 요청을 보내고 응답을 기다리는 시간이 있기 때문에, 응답 시간이 짧으면 같은 VU 수에서도 RPS가 높아지고, 응답이 느리면 RPS가 낮아집니다. 부하 테스트에서는 두 지표를 함께 봐야 실제 시스템의 처리 능력을 정확하게 파악할 수 있습니다.

---

## Q3. p95, p99 같은 백분위 지표를 쓰는 이유는 무엇인가요?

평균 응답 시간은 극단적으로 빠른 요청들이 느린 요청의 영향을 희석시키기 때문에, 실제 사용자 경험을 정확히 반영하지 못합니다. 예를 들어 99개 요청이 10ms에 응답하고 1개가 10초 걸려도 평균은 109ms밖에 안 됩니다. p95는 전체 요청의 95퍼센트가 이 시간 안에 응답된다는 의미이기 때문에, 대부분의 사용자가 체감하는 최악 케이스에 가깝습니다. p99는 더 극단적인 꼬리 지연을 보는 지표고요. 서비스 품질을 판단할 때는 평균보다 백분위 지표가 훨씬 실질적입니다.

---

## Q4. 부하 테스트 시 backlog라는 용어는 무엇을 의미하나요?

메시지 큐나 스트림 기반 시스템에서 backlog는 아직 소비되지 않고 쌓여 있는 메시지 수를 의미합니다. Producer가 이벤트를 발행하는 속도보다 Consumer가 처리하는 속도가 느리면 backlog가 늘어납니다. backlog가 계속 증가하면 메모리 부족이나 처리 지연으로 이어지기 때문에, 부하 테스트에서 backlog가 안정적으로 유지되는지를 확인하는 게 중요합니다. backlog가 0에서 5 정도면 Consumer가 Producer를 충분히 따라가고 있다는 뜻입니다.

---

---

# JVM_GC_메모리

---

## Q1. JVM의 메모리 구조를 간단히 설명해 주세요.

JVM 메모리는 크게 Heap과 Non-Heap으로 나뉩니다. Heap은 객체가 생성되는 영역으로 GC의 대상이 됩니다. Young Generation과 Old Generation으로 나뉘는데, 새로 생성된 객체는 Young에 들어가고, 오래 살아남은 객체는 Old로 이동합니다. Non-Heap에는 클래스 메타데이터가 저장되는 Metaspace, JIT 컴파일된 코드가 저장되는 Code Cache, 스레드별로 할당되는 Stack 등이 있습니다. Spring Boot 같은 애플리케이션을 운영할 때는 Heap 크기 설정이 중요한데, 너무 작으면 GC가 자주 발생하고 너무 크면 GC 시간이 길어질 수 있습니다.

---

## Q2. GC가 왜 필요하고, 주요 GC 알고리즘은 어떤 게 있나요?

Java는 개발자가 직접 메모리를 해제하지 않기 때문에, 더 이상 참조되지 않는 객체를 자동으로 정리하는 GC가 필요합니다. 주요 알고리즘으로는 Serial GC, Parallel GC, G1 GC, ZGC가 있습니다. Serial은 단일 스레드로 GC를 수행해서 소규모 애플리케이션에 적합하고, Parallel은 멀티 스레드로 처리해서 처리량이 높습니다. G1 GC는 Java 9부터 기본 GC로, Heap을 Region 단위로 나눠서 관리하기 때문에 대용량 Heap에서도 예측 가능한 중단 시간을 유지합니다. ZGC는 중단 시간을 밀리초 단위로 제한하는 저지연 GC입니다. 저희 프로젝트는 Spring Boot 2.7 기반이라 G1 GC가 기본 적용되어 있었습니다.

---

## Q3. Stop-the-World란 무엇인가요?

GC가 실행될 때 애플리케이션의 모든 스레드를 일시 정지시키는 현상입니다. GC가 객체 참조 그래프를 정확하게 추적하려면 객체 상태가 변하지 않아야 하기 때문에, 애플리케이션 스레드를 멈추고 GC 작업을 수행합니다. Minor GC는 Young Generation만 대상이라 짧지만, Full GC는 전체 Heap을 대상으로 하기 때문에 중단 시간이 길어질 수 있습니다. 서비스 운영에서 Stop-the-World가 길어지면 응답 지연이나 타임아웃으로 이어질 수 있어서, GC 튜닝의 핵심은 이 중단 시간을 최소화하는 것입니다.

---

## Q4. 메모리 누수는 어떻게 발생하고 어떻게 탐지하나요?

Java에서 메모리 누수는 더 이상 필요 없는 객체인데 어딘가에서 계속 참조하고 있어서 GC가 수거하지 못하는 상황입니다. 대표적으로 static 컬렉션에 객체를 넣고 제거하지 않는 경우, 리스너나 콜백을 등록하고 해제하지 않는 경우, 캐시에 데이터를 넣고 만료 정책이 없는 경우가 있습니다. 탐지는 Heap 사용량 추이를 모니터링해서 GC 후에도 Heap이 지속적으로 증가하면 누수를 의심합니다. Heap Dump를 뜬 뒤 MAT 같은 도구로 분석하면 어떤 객체가 메모리를 점유하고 있는지 확인할 수 있습니다.

---

---

# Redis

---

## Q1. Redis는 왜 빠른가요?

Redis가 빠른 이유는 크게 세 가지입니다. 첫째, 모든 데이터를 메모리에 저장하고 읽기 때문에 디스크 I/O가 없습니다. 둘째, 싱글 스레드 이벤트 루프 모델을 사용해서 컨텍스트 스위칭이나 락 경합이 없습니다. 셋째, 데이터 구조가 해시 테이블, 스킵 리스트 같은 효율적인 자료구조로 구현되어 있어서 대부분의 명령이 O(1)이나 O(log n)에 처리됩니다. 싱글 스레드라서 처리량이 제한될 것 같지만, 네트워크 I/O가 병목인 대부분의 상황에서는 CPU가 아니라 네트워크가 먼저 한계에 도달합니다.

---

## Q2. Redis의 데이터 영속화 방식을 설명해 주세요.

Redis는 메모리 기반이지만 데이터를 디스크에 저장하는 영속화 옵션이 있습니다. RDB는 특정 시점의 스냅샷을 파일로 저장하는 방식으로, 복구 속도가 빠르지만 스냅샷 사이에 발생한 변경은 유실될 수 있습니다. AOF는 모든 쓰기 명령을 로그로 기록하는 방식으로, 데이터 유실이 거의 없지만 파일 크기가 커지고 복구 시간이 길어질 수 있습니다. 두 방식을 병행하는 것도 가능합니다. 저희 프로젝트에서는 세션 데이터의 경우 일시적 유실이 허용 가능했기 때문에 기본 설정을 사용하되, 감사 로깅에서는 AOF를 활용하는 방향으로 설계했습니다.

---

## Q3. Redis Streams는 Kafka와 뭐가 다른가요?

둘 다 메시지 스트리밍을 지원하지만 규모와 복잡도가 다릅니다. Redis Streams는 Redis 서버 안에서 동작하는 가벼운 스트리밍 기능으로, Consumer Group, 메시지 ACK, 순서 보장을 지원합니다. Kafka는 분산 클러스터 기반으로 설계되어 파티션 단위 병렬 처리, 대용량 메시지 영속화, 리플리케이션이 강점입니다. Redis Streams는 별도 인프라 없이 Redis만 있으면 쓸 수 있어서 운영 복잡도가 낮고, 단일 서버 환경에서 적절한 처리량의 이벤트 스트리밍이 필요할 때 적합합니다. 트래픽이 커지면 Kafka로 전환하는 게 맞지만, 저희 프로젝트 규모에서는 Redis Streams가 적절한 선택이었습니다.

---

## Q4. Redis의 TTL과 슬라이딩 세션의 관계를 설명해 주세요.

TTL은 키의 만료 시간을 설정하는 기능으로, 설정된 시간이 지나면 키가 자동으로 삭제됩니다. 슬라이딩 세션은 사용자가 활동할 때마다 세션 만료 시간을 연장하는 방식인데, Redis에서는 EXPIRE 명령으로 TTL을 갱신하면 됩니다. 예를 들어 세션 TTL이 1시간이면, API 요청이 올 때마다 해당 세션 키의 TTL을 다시 1시간으로 리셋합니다. 사용자가 1시간 동안 아무 요청도 안 보내면 TTL이 만료되어 키가 삭제되고, 다음 요청 시 세션이 없으니 인증 실패가 됩니다.

---

---

# JWT_인증

---

## Q1. JWT의 구조와 동작 원리를 설명해 주세요.

JWT는 Header, Payload, Signature 세 부분을 dot으로 연결한 문자열입니다. Header에는 서명 알고리즘 정보, Payload에는 사용자 정보나 만료 시간 같은 클레임, Signature에는 Header와 Payload를 비밀키로 서명한 값이 들어갑니다. 서버가 JWT를 받으면 비밀키로 서명을 검증해서 토큰이 위변조되지 않았는지 확인합니다. Payload는 Base64로 인코딩된 것이지 암호화된 게 아니기 때문에, 민감한 정보를 Payload에 넣으면 안 됩니다. JWT의 장점은 서버가 별도의 세션 저장소 없이도 토큰만으로 인증할 수 있는 Stateless 특성입니다.

---

## Q2. Access Token과 Refresh Token을 분리하는 이유는 무엇인가요?

Access Token 하나만 쓰면 만료 시간을 길게 잡아야 하는데, 토큰이 탈취되면 그 긴 시간 동안 악용될 수 있습니다. 반대로 짧게 잡으면 사용자가 자주 재로그인해야 합니다. 이 딜레마를 해결하기 위해 Access Token은 짧은 만료 시간으로 설정하고, Refresh Token은 길게 설정합니다. Access Token이 만료되면 Refresh Token으로 새 Access Token을 발급받기 때문에, 사용자는 재로그인 없이 이용할 수 있고 보안도 유지됩니다. Access Token이 탈취되어도 짧은 시간 안에 만료되고, Refresh Token은 서버 측 검증을 추가로 거치게 해서 보안을 강화합니다.

---

## Q3. JWT를 LocalStorage에 저장하면 안 되는 이유는 무엇인가요?

LocalStorage는 JavaScript로 자유롭게 접근할 수 있습니다. XSS 공격이 발생하면 공격자가 삽입한 JavaScript가 LocalStorage에서 토큰을 읽어서 외부로 전송할 수 있습니다. HttpOnly 쿠키에 저장하면 JavaScript에서 쿠키 값에 접근할 수 없기 때문에, XSS 공격이 발생하더라도 토큰 자체를 탈취하는 건 불가능합니다. 대신 쿠키 방식은 CSRF 공격에 대비해야 하는데, SameSite 속성과 같은 방어 수단을 적용해서 완화할 수 있습니다.

---

---

# Elasticsearch

---

## Q1. Elasticsearch의 역색인 구조를 설명해 주세요.

일반적인 DB 인덱스는 문서에서 키워드를 찾는 구조라면, 역색인은 키워드에서 문서를 찾는 구조입니다. 문서를 색인할 때 텍스트를 토큰으로 분리하고, 각 토큰이 어떤 문서에 포함되어 있는지를 역으로 매핑해둡니다. 예를 들어 "개발"이라는 토큰에 대해 문서 1, 문서 3, 문서 7에 포함되어 있다는 정보를 저장합니다. 검색할 때는 검색어를 같은 방식으로 토큰화하고, 해당 토큰의 문서 목록을 즉시 가져올 수 있어서 대량의 문서에서도 밀리초 단위로 검색이 가능합니다.

---

## Q2. Nori 형태소 분석기가 필요한 이유는 무엇인가요?

한국어는 조사, 어미 변화가 다양해서 단순 공백 분리로는 정확한 토큰화가 불가능합니다. "개발자가", "개발하는", "개발을" 이런 변형이 전부 "개발"이라는 원형으로 분석되어야 검색이 제대로 됩니다. Nori는 한국어 형태소 분석에 특화된 분석기로, 복합명사 분리도 지원합니다. 예를 들어 "시스템관리자"를 "시스템"과 "관리자"로 분리해서 색인하기 때문에, "시스템 관리"로 검색해도 매칭됩니다. Elasticsearch 공식 플러그인이라 별도 외부 의존성 없이 바로 사용할 수 있다는 장점도 있습니다.

---

## Q3. BM25 알고리즘은 뭔가요?

BM25는 Elasticsearch의 기본 문서 랭킹 알고리즘입니다. TF-IDF를 발전시킨 형태인데, 두 가지 핵심 요소가 있습니다. 첫째, 검색어가 해당 문서에 많이 등장할수록 점수가 높아지지만, 일정 수준 이상에서는 포화되어 무한히 올라가지 않습니다. 이게 TF-IDF와의 차이입니다. 둘째, 검색어가 전체 문서 중 드물게 등장하는 단어일수록 가중치가 높습니다. 거기에 문서 길이 정규화가 포함되어 있어서, 문서가 길다고 무조건 높은 점수를 받지 않습니다. 본문이 긴 게시글과 짧은 메뉴 페이지 간에 공정한 랭킹이 가능한 이유가 이 때문입니다.

---

## Q4. Alias와 인덱스의 관계를 설명해 주세요.

Alias는 인덱스에 대한 별칭입니다. 애플리케이션은 실제 인덱스명 대신 Alias를 통해 쿼리하는데, Alias가 가리키는 인덱스를 바꿀 수 있다는 게 핵심입니다. 재색인할 때 새 인덱스를 만들어서 데이터를 색인하고, 완료되면 Alias만 새 인덱스로 전환하면 검색 서비스 중단 없이 인덱스를 교체할 수 있습니다. Alias 전환은 원자적으로 이루어지기 때문에, 전환 순간에 검색 요청이 실패하는 일이 없습니다. Read용 Alias와 Write용 Alias를 분리하면 재색인 중에도 기존 인덱스로 검색을 계속 서비스할 수 있습니다.

---

---

# Spring_Security

---

## Q1. Spring Security의 Filter Chain은 어떻게 동작하나요?

Spring Security는 서블릿 필터 체인 위에 자체적인 보안 필터 체인을 구성합니다. HTTP 요청이 들어오면 여러 필터를 순서대로 통과하는데, 각 필터가 인증, 세션 관리, CSRF 방어, CORS 처리 같은 특정 보안 관심사를 담당합니다. JWT 인증을 구현할 때는 UsernamePasswordAuthenticationFilter 앞에 커스텀 필터를 추가해서, 쿠키에서 JWT를 추출하고 검증하는 로직을 넣었습니다. 필터 순서가 중요한데, 인증 필터보다 CORS 필터가 먼저 실행되어야 프리플라이트 요청이 인증 없이 통과할 수 있습니다.

---

## Q2. 인증과 인가의 차이는 무엇인가요?

인증은 이 사용자가 누구인지를 확인하는 것이고, 인가는 확인된 사용자가 특정 리소스에 접근할 권한이 있는지를 판단하는 것입니다. 영어로 하면 Authentication과 Authorization인데, Spring Security에서는 이 둘을 명확히 분리합니다. 인증 필터에서 JWT를 검증하고 SecurityContext에 인증 정보를 설정하는 것까지가 인증이고, 그 이후에 PreAuthorize나 PermissionService를 통해 해당 요청에 대한 권한을 확인하는 게 인가입니다. 저희 프로젝트에서는 인증은 JWT + Redis 세션으로, 인가는 계층형 권한 모델로 분리해서 구현했습니다.

---

## Q3. CORS와 CSRF의 차이를 설명해 주세요.

CORS는 Cross-Origin Resource Sharing으로, 브라우저가 다른 출처의 서버에 요청을 보낼 수 있는지를 제어하는 정책입니다. 서버가 응답 헤더로 허용할 출처를 명시하면 브라우저가 그 응답을 받아들입니다. CSRF는 Cross-Site Request Forgery로, 사용자가 로그인한 상태에서 악성 사이트가 사용자 모르게 요청을 보내는 공격입니다. 쿠키가 자동으로 전송되기 때문에 발생하는 문제인데, SameSite 쿠키 속성으로 외부 사이트에서의 쿠키 전송을 제한하면 방어할 수 있습니다. CORS는 서버가 브라우저에게 허용 범위를 알려주는 것이고, CSRF는 쿠키 기반 인증에서 발생하는 공격을 막는 것으로, 둘은 방향이 다릅니다.

---

---

# Gradle_빌드

---

## Q1. Gradle과 Maven의 차이는 무엇인가요?

Maven은 XML 기반의 선언적 빌드 도구이고, Gradle은 Groovy나 Kotlin DSL 기반의 프로그래밍 가능한 빌드 도구입니다. Maven은 정해진 라이프사이클대로 동작하기 때문에 단순한 프로젝트에서는 설정이 적지만, 커스텀 빌드 로직이 필요하면 플러그인을 만들어야 해서 복잡해집니다. Gradle은 스크립트 자체가 프로그래밍 언어라서 조건 분기, Task 의존성 정의, 동적 설정이 자유롭습니다. 성능 면에서도 Gradle은 증분 빌드와 빌드 캐시를 지원해서 변경된 부분만 다시 빌드하기 때문에 대규모 프로젝트에서 빌드 속도가 빠릅니다.

---

## Q2. 어노테이션 프로세싱이란 무엇인가요?

Java 컴파일러가 소스 코드를 컴파일하는 과정에서, 어노테이션을 읽어서 추가 소스 코드나 리소스를 자동으로 생성하는 기능입니다. Lombok은 Getter, Setter 같은 보일러플레이트 코드를 생성하고, MapStruct는 DTO 변환 코드를 생성하고, QueryDSL은 엔티티 기반의 Q클래스를 생성합니다. 이 프로세서들은 컴파일 타임에 실행되기 때문에 런타임 오버헤드가 없다는 장점이 있지만, 여러 프로세서가 동시에 실행될 때 실행 순서가 보장되지 않아서 경합 문제가 생길 수 있습니다.

---

## Q3. 빌드 캐시와 증분 빌드의 차이는 무엇인가요?

증분 빌드는 이전 빌드 이후 변경된 소스 파일만 다시 컴파일하는 것입니다. 파일 A만 수정했으면 파일 A만 컴파일하고 나머지는 이전 결과를 재사용합니다. 빌드 캐시는 한 단계 더 나아가서, Task의 입력값이 동일하면 출력 결과를 캐시에서 가져옵니다. 심지어 다른 브랜치에서 같은 코드를 빌드한 적이 있으면 그 결과를 재사용할 수도 있습니다. 증분 빌드는 연속된 빌드 간의 최적화이고, 빌드 캐시는 빌드 이력 전체에 걸친 최적화라고 볼 수 있습니다.

---

---

# Docker_컨테이너

---

## Q1. Docker 컨테이너와 가상머신의 차이는 무엇인가요?

가상머신은 하이퍼바이저 위에 게스트 OS 전체를 올리기 때문에, OS 부팅 시간과 리소스 오버헤드가 큽니다. Docker 컨테이너는 호스트 OS의 커널을 공유하면서 프로세스 수준의 격리만 제공합니다. 그래서 컨테이너는 수 초 만에 기동되고, 메모리와 디스크 사용량도 훨씬 적습니다. 다만 커널을 공유하기 때문에 보안 격리 수준은 가상머신보다 낮고, 호스트와 다른 OS는 실행할 수 없습니다. 개발 환경 구성이나 마이크로서비스 배포처럼 빠른 기동과 경량화가 중요한 경우에 컨테이너가 적합합니다.

---

## Q2. Docker Compose는 어떤 상황에서 쓰나요?

여러 컨테이너를 함께 실행하고 관리해야 할 때 씁니다. 예를 들어 개발 환경에서 MySQL, Redis, Elasticsearch, 백엔드, 프론트엔드를 동시에 띄워야 하는데, 각각 docker run 명령으로 실행하면 옵션도 복잡하고 순서도 신경 써야 합니다. Docker Compose는 이걸 하나의 YAML 파일로 정의해서 docker compose up 한 명령으로 전체를 기동할 수 있습니다. 서비스 간 네트워크도 자동으로 구성되고, 볼륨, 환경변수, 의존성 순서도 선언적으로 관리할 수 있어서 개발 환경 재현성이 크게 올라갑니다.

---

## Q3. Docker Volume은 왜 필요한가요?

컨테이너는 기본적으로 일시적입니다. 컨테이너를 삭제하면 안에 있던 데이터도 함께 사라집니다. DB 데이터나 업로드 파일처럼 컨테이너 생명주기와 무관하게 유지되어야 하는 데이터는 Volume에 저장해야 합니다. Volume은 호스트 파일시스템의 특정 경로와 컨테이너 내부 경로를 연결하는 건데, 컨테이너를 삭제하고 다시 만들어도 Volume 데이터는 그대로 남습니다. Named Volume을 쓰면 Docker가 관리하는 경로에 자동으로 저장되고, Bind Mount를 쓰면 호스트의 특정 디렉토리를 직접 마운트할 수 있습니다.

---

---

# Nuxt3_SSR

---

## Q1. SSR과 CSR의 차이를 설명해 주세요.

SSR은 서버에서 HTML을 완성해서 브라우저에 내려주는 방식입니다. 브라우저는 이미 완성된 HTML을 받기 때문에 초기 화면이 빠르게 표시되고, 검색 엔진 크롤러도 콘텐츠를 수집할 수 있습니다. CSR은 브라우저가 빈 HTML을 받고 JavaScript가 실행되면서 화면을 그리는 방식입니다. 초기 로딩은 느리지만, 이후 페이지 전환이 빠르고 인터랙션이 매끄럽습니다. Nuxt 3에서는 모든 페이지가 SSR로 첫 렌더링을 하고, 이후 Hydration을 거쳐 CSR로 전환되는 하이브리드 방식을 쓰기 때문에 양쪽의 장점을 모두 가져갈 수 있습니다.

---

## Q2. Hydration이 뭔가요?

SSR로 만들어진 HTML은 정적인 마크업입니다. 이걸 브라우저에서 Vue 앱으로 살려내는 과정이 Hydration입니다. 서버가 보낸 HTML 위에 Vue가 이벤트 리스너를 붙이고, 반응형 데이터를 연결해서 인터랙티브한 SPA로 만드는 거라고 보면 됩니다. 이때 서버에서 만든 HTML과 클라이언트에서 Vue가 다시 만든 DOM이 일치해야 하는데, 일치하지 않으면 Hydration Mismatch가 발생합니다. Mismatch가 생기면 Vue가 기존 HTML을 버리고 다시 렌더링하기 때문에 성능 저하와 화면 깜빡임이 발생할 수 있습니다.

---

## Q3. Nuxt 3의 미들웨어는 Express 미들웨어와 뭐가 다른가요?

Express 미들웨어는 서버 측에서만 실행되는 HTTP 요청 처리 파이프라인입니다. Nuxt 3의 라우트 미들웨어는 SSR과 CSR 양쪽에서 모두 실행됩니다. 서버에서 첫 렌더링할 때 한 번, 브라우저에서 Hydration 후 클라이언트 네비게이션 시 또 한 번 실행됩니다. 그래서 Nuxt 미들웨어 안에서는 현재 서버 환경인지 클라이언트 환경인지를 확인하고 분기 처리를 해야 합니다. 저희 프로젝트에서 SSR과 CSR에서의 리다이렉트 루프 방지 같은 처리가 필요했던 이유가 이 때문입니다.

---

---

# Transactional_Outbox_패턴

---

## Q1. Transactional Outbox 패턴이 해결하는 문제는 무엇인가요?

DB와 외부 시스템에 동시에 변경을 반영해야 할 때 생기는 분산 트랜잭션 문제를 해결합니다. 예를 들어 게시글을 DB에 저장하고 Elasticsearch에도 색인해야 하는데, DB에는 저장됐는데 ES 색인이 실패하거나 그 반대 상황이 생길 수 있습니다. Outbox 패턴은 비즈니스 데이터 저장과 이벤트 기록을 같은 DB 트랜잭션에 넣어서, 둘 다 성공하거나 둘 다 실패하게 만듭니다. 별도 프로세스가 Outbox 테이블에서 이벤트를 읽어서 외부 시스템에 반영하기 때문에, 일관성을 보장하면서도 느슨한 결합을 유지할 수 있습니다.

---

## Q2. Outbox 패턴에서 이벤트 처리 순서는 보장되나요?

Outbox 테이블에 기록된 순서대로 폴링하면 기본적으로 순서가 보장됩니다. 다만 Consumer가 여러 개이거나, 재시도 로직이 있으면 순서가 꼬일 수 있습니다. 만약 순서 보장이 중요하다면 같은 엔티티에 대한 이벤트는 같은 Consumer가 처리하도록 파티셔닝하거나, 낙관적 락으로 순서를 강제해야 합니다. 저희 프로젝트에서는 단일 Consumer로 운영했기 때문에 폴링 순서대로 처리되어 순서 문제는 발생하지 않았습니다.

---

---

# AOP

---

## Q1. AOP가 뭔가요? 왜 쓰나요?

AOP는 Aspect Oriented Programming으로, 여러 모듈에 걸쳐 반복되는 횡단 관심사를 분리하는 프로그래밍 기법입니다. 로깅, 트랜잭션, 보안, 성능 측정 같은 기능은 비즈니스 로직과 직접 관련은 없지만 여러 곳에서 필요합니다. 이런 걸 각 메서드마다 직접 넣으면 코드 중복이 심해지고, 수정할 때도 전부 찾아서 바꿔야 합니다. AOP를 쓰면 이런 공통 로직을 한 곳에 정의하고, 어노테이션이나 포인트컷으로 적용 대상을 지정할 수 있어서 비즈니스 코드를 깔끔하게 유지할 수 있습니다.

---

## Q2. Spring AOP와 AspectJ의 차이는 무엇인가요?

Spring AOP는 프록시 기반으로 동작합니다. 대상 객체를 감싸는 프록시를 만들어서, 메서드 호출 시 프록시가 먼저 가로채는 방식입니다. 그래서 스프링 빈의 public 메서드에만 적용할 수 있고, 같은 객체 내부에서 자기 메서드를 호출하면 프록시를 거치지 않기 때문에 AOP가 동작하지 않습니다. AspectJ는 컴파일 타임이나 로드 타임에 바이트코드를 직접 조작해서 위빙하기 때문에, private 메서드나 필드 접근, 생성자 호출까지 가로챌 수 있습니다. 다만 설정이 복잡하고 빌드 과정이 추가됩니다. 대부분의 경우 Spring AOP로 충분하기 때문에 저희 프로젝트에서도 Spring AOP를 사용했습니다.

---

---

# Blue_Green_배포

---

## Q1. Blue/Green 배포의 원리를 설명해 주세요.

현재 운영 중인 환경을 Blue, 새로 배포할 환경을 Green이라고 부릅니다. Green에 새 버전을 배포하고 정상 동작을 확인한 뒤, 트래픽을 Blue에서 Green으로 전환합니다. 전환이 완료되면 Blue는 대기 상태가 됩니다. 문제가 생기면 트래픽을 다시 Blue로 돌리면 되니까 롤백이 빠릅니다. 핵심은 두 환경이 동시에 존재하고, 로드밸런서나 리버스 프록시가 트래픽 방향만 바꿔주는 것입니다. 저희는 단일 서버에서 포트를 다르게 써서 Blue/Green을 구현했는데, Nginx 설정으로 upstream 포트를 전환하는 방식이었습니다.

---

## Q2. Canary 배포와 Rolling 배포는 Blue/Green과 뭐가 다른가요?

Canary 배포는 새 버전으로 전체 트래픽을 한 번에 보내는 게 아니라, 일부 트래픽만 먼저 보내서 문제가 없는지 확인한 뒤 점진적으로 비율을 늘리는 방식입니다. 예를 들어 처음에 5퍼센트만 새 버전으로 보내고, 이상 없으면 30, 50, 100퍼센트로 늘립니다. Rolling 배포는 여러 인스턴스를 순차적으로 하나씩 교체하는 방식입니다. 인스턴스 A를 내리고 새 버전으로 올리고, 다음에 B를 내리고 올리는 식입니다. Blue/Green은 전환이 한 번에 이루어지고 롤백도 즉각적인 반면, Canary는 점진적 검증이 강점이고 Rolling은 리소스를 절약할 수 있습니다.

---

---

# 네트워크_보안

---

## Q1. HTTPS가 어떻게 동작하는지 간단히 설명해 주세요.

HTTPS는 HTTP에 TLS 암호화를 더한 것입니다. 클라이언트가 서버에 접속하면 먼저 TLS 핸드셰이크가 이루어집니다. 서버가 인증서를 보내면 클라이언트가 이 인증서를 검증하고, 양측이 대칭키를 교환합니다. 이후의 모든 통신은 이 대칭키로 암호화됩니다. 인증서는 공개키 기반으로, 인증서에 포함된 공개키로 암호화하면 서버의 개인키로만 복호화할 수 있습니다. 이 과정을 통해 통신 내용이 중간에서 도청되거나 변조되는 걸 방지하고, 접속한 서버가 진짜 그 서버인지 신원을 검증할 수 있습니다.

---

## Q2. XSS와 CSRF 공격의 차이를 설명해 주세요.

XSS는 Cross-Site Scripting으로, 공격자가 웹 페이지에 악성 JavaScript를 삽입하는 공격입니다. 게시판에 스크립트를 작성하면, 그 게시글을 보는 사용자의 브라우저에서 악성 코드가 실행되어 쿠키 탈취나 개인정보 유출이 발생할 수 있습니다. CSRF는 Cross-Site Request Forgery로, 사용자가 로그인한 상태를 이용해서 악성 사이트가 사용자 모르게 요청을 보내는 공격입니다. XSS는 사용자의 브라우저에서 악성 코드를 실행하는 것이고, CSRF는 사용자의 인증된 세션을 도용하는 것이 핵심 차이입니다. XSS는 입력값 정제와 HttpOnly 쿠키로, CSRF는 SameSite 쿠키나 CSRF 토큰으로 방어합니다.

---

## Q3. SameSite 쿠키 속성의 Strict, Lax, None의 차이는 무엇인가요?

Strict는 외부 사이트에서 유도된 모든 요청에서 쿠키를 전송하지 않습니다. 가장 안전하지만, 외부 링크를 클릭해서 사이트에 들어오면 로그인이 안 되어 있는 상태가 됩니다. Lax는 GET 요청처럼 안전한 요청에서는 쿠키를 전송하고, POST 같은 상태 변경 요청에서는 전송하지 않습니다. 외부 링크 클릭 시에는 로그인이 유지되면서 CSRF 공격의 위험은 줄여줍니다. None은 모든 요청에서 쿠키를 전송하는데, 반드시 Secure 속성과 함께 사용해야 합니다. 저희 프로젝트에서는 SSR과 CSR이 혼합된 환경에서 인증 쿠키가 안정적으로 전달되면서도 CSRF를 방어하기 위해 Lax를 선택했습니다.

---

---

# 데이터베이스

---

## Q1. 인덱스가 왜 필요하고 어떻게 동작하나요?

인덱스 없이 데이터를 검색하면 테이블의 모든 행을 처음부터 끝까지 스캔해야 합니다. 이걸 Full Table Scan이라 하는데, 데이터가 많아지면 매우 느립니다. 인덱스는 특정 컬럼의 값을 정렬된 구조로 별도 저장해서, 원하는 데이터를 빠르게 찾을 수 있게 합니다. B-Tree 인덱스가 가장 일반적인데, 트리 구조를 타고 내려가서 원하는 값의 위치를 로그 시간에 찾습니다. 다만 인덱스를 만들면 INSERT, UPDATE, DELETE 시 인덱스도 함께 갱신해야 하기 때문에 쓰기 성능이 약간 떨어집니다. 읽기가 빈번한 컬럼에 인덱스를 만들고, 모든 컬럼에 무분별하게 만들지 않는 게 중요합니다.

---

## Q2. 트랜잭션의 ACID 속성을 설명해 주세요.

Atomicity는 원자성으로, 트랜잭션 내 작업이 모두 성공하거나 모두 실패해야 한다는 것입니다. Consistency는 일관성으로, 트랜잭션 전후로 데이터가 정의된 규칙을 만족해야 합니다. Isolation은 격리성으로, 동시에 실행되는 트랜잭션들이 서로 영향을 주지 않아야 합니다. Durability는 지속성으로, 커밋된 데이터는 시스템 장애가 발생해도 유지되어야 합니다. 실무에서는 격리 수준을 조절해서 성능과 일관성 사이의 균형을 잡는 게 중요한데, 기본적으로 READ COMMITTED를 많이 쓰고, 필요에 따라 REPEATABLE READ로 올립니다.

---

## Q3. DDL과 DML의 차이는 무엇이고, 왜 DDL은 트랜잭션 롤백이 안 되나요?

DML은 데이터를 조작하는 INSERT, UPDATE, DELETE 같은 명령이고, DDL은 테이블 구조를 변경하는 CREATE, ALTER, DROP 같은 명령입니다. 대부분의 DB에서 DDL은 실행 즉시 암시적으로 커밋되거나 트랜잭션 범위에 포함되지 않습니다. 이유는 DDL이 카탈로그라는 시스템 메타데이터를 변경하는 작업이고, 이 메타데이터는 다른 모든 트랜잭션이 참조하기 때문에 중간 상태로 남겨두면 전체 시스템에 영향을 줄 수 있기 때문입니다. 저희 프로젝트에서 동적 게시판 생성 시 보상 롤백을 직접 구현해야 했던 이유가 바로 DDL이 트랜잭션 롤백 대상이 아니기 때문입니다.

---

---

# 디자인_패턴_및_설계_원칙

---

## Q1. 포트-어댑터 패턴이란 무엇인가요?

핵심 비즈니스 로직과 외부 시스템 사이에 인터페이스를 두는 패턴입니다. 포트는 비즈니스 로직이 외부와 통신하기 위해 정의한 인터페이스이고, 어댑터는 그 인터페이스를 실제 외부 시스템에 맞게 구현한 것입니다. 예를 들어 IP 접근 검사라는 포트를 정의하고, 현재는 CIDR 매칭 어댑터로 구현하지만, 나중에 WAF로 이관하면 WAF 어댑터로 교체하기만 하면 됩니다. 비즈니스 로직은 포트만 알고 어댑터는 모르기 때문에, 외부 시스템이 바뀌어도 비즈니스 로직은 수정할 필요가 없습니다.

---

## Q2. Circuit Breaker 패턴은 어떤 문제를 해결하나요?

외부 서비스에 장애가 발생했을 때, 매번 요청을 보내면서 타임아웃을 기다리는 건 리소스 낭비이고 전체 시스템 성능까지 떨어뜨립니다. Circuit Breaker는 전기 차단기처럼, 실패가 일정 횟수 이상 발생하면 회로를 개방해서 더 이상 요청을 보내지 않고 즉시 실패를 반환합니다. 일정 시간이 지나면 반개방 상태로 전환해서 시험 요청을 보내보고, 성공하면 다시 닫습니다. 저희 프로젝트에서는 Elasticsearch 검색 서비스에 Circuit Breaker를 적용해서, ES 장애 시 CMS 핵심 기능에는 영향이 가지 않도록 격리했습니다.

---

## Q3. Graceful Degradation이란 무엇인가요?

시스템 일부에 장애가 발생했을 때 전체 서비스를 중단하지 않고, 기능을 축소해서라도 서비스를 계속 제공하는 전략입니다. 완벽한 서비스를 제공할 수 없으면 차선의 서비스라도 제공하겠다는 것입니다. 저희 프로젝트에서는 Redis 장애 시 인증 시스템이 완전히 멈추는 대신, JWT 자체 검증으로 제한적인 인증을 유지하되 권한을 최소로 강등하는 방식을 적용했습니다. 보안 수준이 일시적으로 낮아지는 트레이드오프가 있지만, 서비스 전체가 중단되는 것보다는 나은 선택입니다.

---

---

# Git_버전_관리

---

## Q1. merge와 rebase의 차이는 무엇인가요?

merge는 두 브랜치의 변경 사항을 합치면서 merge 커밋을 만듭니다. 브랜치 히스토리가 그대로 보존되기 때문에 언제 어떤 브랜치에서 합쳐졌는지 추적할 수 있지만, 히스토리가 복잡해집니다. rebase는 현재 브랜치의 커밋들을 대상 브랜치 뒤에 다시 붙이는 것으로, 히스토리가 일직선으로 깔끔해집니다. 다만 이미 공유된 커밋을 rebase하면 다른 사람의 히스토리가 꼬일 수 있어서, 원격에 push한 커밋은 rebase하면 안 됩니다. 저희 프로젝트에서는 main 브랜치의 선형 히스토리를 유지하기 위해 fast-forward only 머지 정책을 사용했습니다.

---

## Q2. fast-forward merge란 무엇인가요?

feature 브랜치가 main에서 분기한 이후에 main에 새로운 커밋이 없을 때, merge하면 main 포인터를 feature의 최신 커밋으로 단순히 앞으로 옮기기만 하는 것입니다. 별도의 merge 커밋이 생기지 않고 히스토리가 일직선으로 유지됩니다. 만약 main에 새 커밋이 있으면 fast-forward가 안 되는데, fast-forward only 정책을 쓰면 이 경우 merge를 거부합니다. 이때는 feature 브랜치를 main 위에 rebase한 뒤 다시 merge해야 합니다. 이렇게 하면 main 히스토리가 항상 선형으로 유지되어 커밋 추적이 쉬워집니다.