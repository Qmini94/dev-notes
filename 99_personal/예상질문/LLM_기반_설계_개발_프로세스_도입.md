## Q1. LLM 기반 개발 프로세스를 도입하게 된 배경은 무엇인가요?

사내 클라이언트 접수 관리 시스템을 새로 개발하는 프로젝트가 있었는데, AI 기반 개발 방식을 적용해달라는 요구가 있었습니다. 그런데 팀 내에 CLI 환경에서 LLM을 실제 설계와 개발 워크플로에 적용해본 경험자가 없었습니다. 단순히 코드 자동완성이나 질의응답 수준이 아니라, 요구사항 분석부터 설계, 코드 생성, 검증까지 체계적으로 LLM을 활용하는 프로세스가 필요했기 때문에 제가 주도적으로 도입을 진행하게 되었습니다.

---

## Q2. Claude Code CLI와 BMad 에이전트 프레임워크를 선택한 이유는 무엇인가요?

Claude Code는 CLI 환경에서 프로젝트 컨텍스트를 이해하면서 코드를 생성하고 수정할 수 있는 도구입니다. IDE 플러그인 방식보다 프로젝트 전체 구조를 넓게 파악하면서 작업할 수 있다는 장점이 있었습니다. BMad 에이전트 프레임워크는 소프트웨어 개발의 각 단계를 에이전트 역할로 분리해서 표준화된 산출물을 만들어가는 구조입니다. 예를 들어 요구사항 분석 에이전트, 아키텍처 설계 에이전트, 구현 에이전트 같은 식으로 역할이 나뉘어 있어서, LLM이 각 단계에서 일관된 형식의 마크다운 산출물을 생성할 수 있습니다. 이 두 가지를 결합하면 설계부터 구현까지 체계적으로 LLM을 활용할 수 있다고 판단했습니다.

---

## Q3. MD 산출물 기반의 표준화된 설계 프로세스란 구체적으로 어떤 건가요?

각 설계 단계의 결과물을 정해진 형식의 마크다운 문서로 관리하는 프로세스입니다. 요구사항 정의서, 도메인 모델, API 명세, 아키텍처 결정 기록 같은 문서를 단계별로 생성하고, 다음 단계의 LLM 입력으로 활용합니다. 예를 들어 요구사항 문서를 기반으로 도메인 모델을 생성하고, 도메인 모델을 기반으로 API 명세를 만드는 식입니다. 마크다운이기 때문에 Git으로 버전 관리가 되고, LLM이 읽고 쓰기에도 적합합니다. 사람이 중간에 리뷰하고 수정한 내용이 다음 단계에 자연스럽게 반영되기 때문에, LLM에게 전부 맡기는 게 아니라 사람과 LLM이 협업하는 구조가 됩니다.

---

## Q4. 서브 에이전트를 활용한 재검증 단계는 어떻게 동작하나요?

LLM이 생성한 설계 문서나 코드 초안을 다른 역할의 에이전트가 검증하는 구조입니다. 예를 들어 구현 에이전트가 코드를 생성하면, 리뷰 에이전트가 해당 코드를 설계 문서와 대조해서 누락된 요구사항이나 설계 위반 사항을 체크합니다. 아키텍처 설계를 생성한 뒤에도 별도 검증 에이전트가 일관성, 실현 가능성, 누락 항목을 확인합니다. 같은 LLM이라도 역할과 프롬프트가 다르면 다른 관점에서 검토하기 때문에, 단일 패스로 생성한 것보다 품질이 눈에 띄게 올라갔습니다. 사람이 최종 리뷰를 하기 전에 기계적인 검증을 한 단계 거치는 셈입니다.

---

## Q5. LLM이 생성한 코드의 품질은 실제로 어느 수준이었나요?

솔직히 말하면 LLM이 생성한 코드를 그대로 쓸 수 있는 경우는 많지 않았습니다. 다만 초안으로서의 가치가 컸습니다. 전체 구조와 보일러플레이트 코드, API 엔드포인트 스캐폴딩 같은 부분은 빠르게 만들어주기 때문에, 개발자가 비즈니스 로직과 엣지 케이스 처리에 집중할 수 있었습니다. 서브 에이전트 검증과 사람 리뷰를 거치면서 점진적으로 수정하는 방식이 효과적이었고, 특히 설계 문서 생성에서는 빠뜨리기 쉬운 항목을 체계적으로 나열해주는 게 큰 도움이 되었습니다.

---

## Q6. 이 프로세스 도입으로 실제 어떤 효과가 있었나요?

가장 큰 효과는 설계 문서 작성과 초기 개발 시간 단축이었습니다. 요구사항을 정리하고 설계 문서를 처음부터 쓰는 것과, LLM이 만든 초안을 리뷰하면서 수정하는 것은 소요 시간이 크게 다릅니다. 또한 설계 의사결정의 일관성이 확보되었습니다. 마크다운 산출물이 체인처럼 연결되어 있어서, 앞 단계의 결정이 뒷 단계에 자동으로 반영되기 때문에 설계가 중간에 엇나가는 일이 줄었습니다. 신규 기능을 확장할 때도 기존 설계 문서를 컨텍스트로 넣어주면 일관된 방향으로 설계가 이어지는 효과가 있었습니다.

---

## Q7. 이 프로세스를 팀에 정착시키는 과정에서 어려운 점은 없었나요?

LLM 출력물에 대한 신뢰도 조절이 가장 어려웠습니다. 처음에는 LLM이 만든 결과를 너무 신뢰하거나, 반대로 전혀 신뢰하지 않는 양극단이 있었습니다. LLM은 그럴듯하지만 틀린 내용을 자신있게 말하는 경우가 있기 때문에, 어떤 부분은 믿을 수 있고 어떤 부분은 반드시 검증해야 하는지 기준을 세우는 게 중요했습니다. 구조적인 부분이나 패턴 적용은 비교적 신뢰할 수 있지만, 도메인 특화 로직이나 엣지 케이스는 반드시 사람이 검증해야 한다는 가이드라인을 만들어서 팀에 공유했습니다.

---

## Q8. 기존에 하던 개발 방식과 비교했을 때 가장 큰 차이는 무엇인가요?

가장 큰 차이는 설계와 개발의 시작점이 바뀐다는 것입니다. 기존에는 빈 문서에서 시작해서 한 줄 한 줄 채워나가는 방식이었다면, 이 프로세스에서는 LLM이 만든 초안을 기반으로 검토하고 수정하는 방식으로 바뀝니다. 창작보다 편집에 가까운 작업이 되는 거라서, 개발자의 역할이 코드를 처음부터 작성하는 것에서 설계 판단과 품질 검증에 더 집중하는 쪽으로 이동합니다. 다만 이게 효과를 내려면 LLM에게 좋은 컨텍스트를 제공하는 능력이 중요해지기 때문에, 프롬프트 설계와 산출물 구조화 역량이 새롭게 필요해집니다.

---

## Q9. 이 프로세스에서 개선하고 싶은 점이 있다면 무엇인가요?

두 가지를 개선하고 싶습니다. 첫째, 현재는 각 단계의 산출물을 수동으로 다음 단계에 전달하고 있는데, 파이프라인을 자동화해서 요구사항 입력부터 설계 검증까지 한 번에 흐르게 만들면 효율이 더 올라갈 것입니다. 둘째, LLM이 생성한 코드에 대한 자동 테스트 생성과 실행을 검증 단계에 포함시키고 싶습니다. 현재는 서브 에이전트가 텍스트 기반으로 검토하는 수준인데, 실제 테스트를 돌려서 동작을 검증하는 단계까지 추가하면 코드 품질 보장이 더 강화될 것입니다. 이런 개선을 통해 LLM 기반 개발 프로세스의 자동화 수준과 품질 보장 체계를 한 단계 더 높일 수 있을 것입니다.